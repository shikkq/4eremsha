import requests
import time
import re
import json
import os
from datetime import datetime, timedelta
from dotenv import load_dotenv
from database import add_shelter
from urllib.parse import quote_plus

load_dotenv()

VK_TOKEN = os.getenv("VK_TOKEN")
VK_KEYWORDS = os.getenv("VK_KEYWORDS", "–ø—Ä–∏—é—Ç,–≤–æ–ª–æ–Ω—Ç,–∂–∏–≤–æ—Ç–Ω,–∫–æ—à–∫,—Å–æ–±–∞–∫,—Ö–≤–æ—Å—Ç,–ø–æ–º–æ—â—å,–Ω—É–∂–Ω,—Å—Ä–æ—á–Ω–æ,–ø–æ–º–æ–≥–∏—Ç–µ,–ø–æ–¥–¥–µ—Ä–∂–∫–∞").split(",")
VK_API_VERSION = "5.199"
CACHE_FILE = "parsed_groups.json"

if os.path.exists(CACHE_FILE):
    with open(CACHE_FILE, "r", encoding="utf-8") as f:
        parsed_groups = set(json.load(f))
else:
    parsed_groups = set()

def save_cache():
    with open(CACHE_FILE, "w", encoding="utf-8") as f:
        json.dump(list(parsed_groups), f)

def get_city_id(city_name):
    url = "https://api.vk.com/method/database.getCities"
    params = {
        "access_token": VK_TOKEN,
        "country_id": 1,
        "q": city_name,
        "count": 1,
        "v": VK_API_VERSION
    }
    res = requests.get(url, params=params).json()
    items = res.get("response", {}).get("items", [])
    return items[0]["id"] if items else None

def contains_keywords(text):
    lowered = text.lower()
    return any(kw.lower() in lowered for kw in VK_KEYWORDS)

def contains_city(text, city_name):
    lowered = text.lower()
    city_lower = city_name.lower()
    if f"–≥. {city_lower}" in lowered:
        return True
    if re.search(rf"\b{re.escape(city_lower)}\b", lowered):
        return True
    return False

def normalize_contacts(contacts):
    cleaned = set()
    for contact in contacts:
        # –£–¥–∞–ª—è–µ–º –≤—Å–µ –Ω–µ—Ü–∏—Ñ—Ä–æ–≤—ã–µ —Å–∏–º–≤–æ–ª—ã, –∫—Ä–æ–º–µ + –¥–ª—è –Ω–æ–º–µ—Ä–æ–≤
        normalized = re.sub(r"[^\d+]", "", contact)
        if len(normalized) == 11 and normalized.startswith("8"):
            normalized = "+7" + normalized[1:]
        cleaned.add(normalized)
    return cleaned

def extract_info_from_posts(posts_texts, city_name):
    """
    –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –ø–æ—Å—Ç–æ–≤ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ª—É—á—à–∏–π –≤–∞—Ä–∏–∞–Ω—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏, 
    —Å–æ–¥–µ—Ä–∂–∞—â–∏–π –¥–∞—Ç—É –ø–æ—Å—Ç–∞, –±–ª–æ–∫ "–ß—Ç–æ –Ω—É–∂–Ω–æ:", –∫–æ–Ω—Ç–∞–∫—Ç—ã –∏ –∞–¥—Ä–µ—Å, –µ—Å–ª–∏ –æ–Ω–∏ –Ω–∞–π–¥–µ–Ω—ã.
    –ï—Å–ª–∏ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å (score) –º–µ–Ω—å—à–µ –ø–æ—Ä–æ–≥–æ–≤–æ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è, –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç—Å—è None.
    """
    keyword_found = False
    best_info = None
    best_score = 0

    help_keywords = ["–Ω—É–∂–Ω—ã", "–Ω—É–∂–µ–Ω", "–Ω—É–∂–Ω–∞—è", "–Ω—É–∂–Ω–æ–µ", "–ø–æ–º–æ—â—å", "–ø–æ–º–æ–≥–∏—Ç–µ", "—Å—Ä–æ—á–Ω–æ", "—Å–±–æ—Ä", "–ø–æ–¥–¥–µ—Ä–∂–∫–∞"]
    contact_patterns = [
        r"\+7[\d\-\s]{10,15}",
        r"\b8[\d\-\s]{9,15}",
        r"[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\.[a-zA-Z0-9-.]+",
        r"https?://[^\s]+"
    ]
    address_keywords = ["—É–ª.", "—É–ª–∏—Ü–∞", "–ø—Ä–æ—Å–ø–µ–∫—Ç", "–±—É–ª—å–≤–∞—Ä", "–ø–µ—Ä–µ—É–ª–æ–∫", "–ø–æ –∞–¥—Ä–µ—Å—É", "–¥–≤–æ—Ä", "–º–µ—Å—Ç–æ –≤—Å—Ç—Ä–µ—á–∏", "–∞–¥—Ä–µ—Å"]

    for post in posts_texts:
        text = post.get("text", "")
        lowered = text.lower()

        if not contains_keywords(text):
            continue

        if city_name and not contains_city(text, city_name):
            continue

        keyword_found = True
        score = 0
        contacts = set()
        addresses = set()
        info_lines = []

        post_date_unix = post.get("date")
        post_date = datetime.fromtimestamp(post_date_unix)
        last_date = post_date.strftime("%d.%m.%Y") if post_date_unix else "–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –Ω–µ–∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å
        fourteen_days_ago = datetime.now() - timedelta(days=14)
        post_date = datetime.fromtimestamp(post_date_unix)
        is_inactive = post_date < fourteen_days_ago
        if is_inactive:
            score -= 3
        contacts = normalize_contacts(contacts)

        if any(kw in lowered for kw in address_keywords):
            snippet = text[:300]
            if 10 < len(snippet) < 300:
                addresses.add(snippet)
                score += 2

        if any(kw in lowered for kw in ["–ø—Ä–∏—é—Ç", "–∂–∏–≤–æ—Ç–Ω", "—Å–æ–±–∞–∫", "–∫–æ—à–∫", "—Ö–≤–æ—Å—Ç", "–≤–æ–ª–æ–Ω—Ç"]):
            score += 1
        if city_name and contains_city(text, city_name):
            score += 1

        # –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –∏—Ç–æ–≥–æ–≤–æ–≥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
        if score >= best_score:
            best_score = score
            result = f"\U0001F4C5 –î–∞—Ç–∞ –ø–æ—Å—Ç–∞: {last_date}\n\n"
            if info_lines:
                result += "\U0001F4CC –ß—Ç–æ –Ω—É–∂–Ω–æ:\n" + "\n".join(info_lines[:2]) + "\n"
            if contacts:
                result += "\n\U0001F4DE –ö–æ–Ω—Ç–∞–∫—Ç—ã:\n" + "\n".join(contacts) + "\n"
            if addresses:
                result += "\n\U0001F4CD –ê–¥—Ä–µ—Å –∏–ª–∏ –º–µ—Å—Ç–æ:\n" + "\n".join(addresses) + "\n"

            # –£–±–∏—Ä–∞–µ–º –≤—ã–≤–æ–¥ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ —Å–æ–≥–ª–∞—Å–Ω–æ –¢–ó

            if not contacts or not addresses:
                result += "\n‚ö†Ô∏è –ü–æ—Å—Ç –º–æ–∂–µ—Ç –±—ã—Ç—å –Ω–µ–ø–æ–ª–Ω—ã–º ‚Äî –ø—Ä–æ–≤–µ—Ä—å—Ç–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –≤—Ä—É—á–Ω—É—é.\n"

            best_info = result.strip()

    if not keyword_found:
        print("‚ùå –í –ø–æ—Å—Ç–∞—Ö –Ω–µ—Ç –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ ‚Äî –ø—Ä–æ–ø—É—Å–∫–∞–µ–º.")
        return None
    if best_score < 5:
        print(f"‚ö†Ô∏è –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –±–∞–ª–ª–æ–≤ (score={best_score}) ‚Äî –ø—Ä–æ–ø—É—Å–∫–∞–µ–º.")
        return None

    return best_info

def get_group_posts(group_id):
    url = "https://api.vk.com/method/wall.get"
    params = {
        "access_token": VK_TOKEN,
        "owner_id": -group_id,
        "count": 10,
        "filter": "owner",
        "v": VK_API_VERSION
    }
    try:
        res = requests.get(url, params=params).json()
        posts = res.get("response", {}).get("items", [])
        result = []
        fourteen_days_ago = datetime.now() - timedelta(days=14)

        for post in posts:
            date_unix = post.get("date")
            text = post.get("text", "")
            post_id = post.get("id")
            if date_unix and text and len(text) > 50:
                post_date = datetime.fromtimestamp(date_unix)
                if post_date > fourteen_days_ago:
                    result.append({"id": post_id, "date": date_unix, "text": text})

        if not result and posts:
            latest_post = posts[0]
            return [{
                "id": latest_post.get("id"),
                "date": latest_post.get("date"),
                "text": f"(–Ω–µ–∞–∫—Ç–∏–≤–Ω–æ)\n{latest_post.get('text', '')[:400]}"
            }]

        return result

    except Exception as e:
        print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –ø–æ—Å—Ç–æ–≤ –≥—Ä—É–ø–ø—ã {group_id}: {e}")
        return []


def search_vk_groups(city_name):
    start = time.time()
    print(f"\nüîç [VK] –ù–∞—á–∏–Ω–∞—é –ø–∞—Ä—Å–∏–Ω–≥ –≥–æ—Ä–æ–¥–∞: {city_name}")

    city_id = get_city_id(city_name)
    if not city_id:
        print(f"‚ùå –ì–æ—Ä–æ–¥ '{city_name}' –Ω–µ –Ω–∞–π–¥–µ–Ω.")
        return

    total_processed = 0
    total_groups_checked = 0

    exclusion_keywords = [
        # ... (—Å–ø–∏—Å–æ–∫ –∏—Å–∫–ª—é—á–µ–Ω–∏–π –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π)
    ]

    # –£–ª—É—á—à–µ–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤
    VK_KEYWORDS = [kw.strip() for kw in VK_KEYWORDS]

    for keyword in VK_KEYWORDS:
        offset = 0
        while total_processed < 10:
            # –≠–∫—Ä–∞–Ω–∏—Ä—É–µ–º –≥–æ—Ä–æ–¥ –¥–ª—è –ø–æ–∏—Å–∫–∞
            encoded_city = quote_plus(city_name)
            url = "https://api.vk.com/method/groups.search"
            params = {
                "access_token": VK_TOKEN,
                "q": f"{keyword} {encoded_city}",
                "count": 20,
                "sort": 0,
                "offset": offset,
                "city_id": city_id,
                "v": VK_API_VERSION
            }
            try:
                res = requests.get(url, params=params).json()
                if 'error' in res:
                    print(f"‚ùå –û—à–∏–±–∫–∞ API: {res['error']['error_msg']}")
                    break
                groups = res.get("response", {}).get("items", [])
            except Exception as e:
                print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ: {e}")
                break

            if not groups:
                break

            for group in groups:
                # ... (–ø—Ä–æ–≤–µ—Ä–∫–∏ –≥—Ä—É–ø–ø—ã –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π –¥–æ —É—Å–ª–æ–≤–∏—è parsed_groups)

                # –û—Å–ª–∞–±–ª—è–µ–º –ø—Ä–æ–≤–µ—Ä–∫—É –Ω–∞–∑–≤–∞–Ω–∏—è –≥—Ä—É–ø–ø—ã
                if any(x in lowered_name for x in exclusion_keywords):
                    print(f"‚õî –ì—Ä—É–ø–ø–∞ '{group_name}' ‚Äî –Ω–µ –ø–æ —Ç–µ–º–µ ‚Äî –ø—Ä–æ–ø—É—Å–∫–∞–µ–º.")
                    continue

                # –ü–µ—Ä–µ–Ω–æ—Å–∏–º —á–∞—Å—Ç—å –ø—Ä–æ–≤–µ—Ä–æ–∫ –≤ –∞–Ω–∞–ª–∏–∑ –ø–æ—Å—Ç–æ–≤
                print(f"üîπ –ü—Ä–æ–≤–µ—Ä—è–µ–º –≥—Ä—É–ø–ø—É: {group_name}")
                group_link = f"https://vk.com/{group['screen_name']}"
                post_texts = get_group_posts(group_id)
                time.sleep(0.34)

                if not post_texts:
                    print("‚ö†Ô∏è –ù–µ—Ç –ø–æ—Å—Ç–æ–≤ ‚Äî –ø—Ä–æ–ø—É—Å–∫–∞–µ–º.")
                    continue

                # –î–æ–±–∞–≤–ª—è–µ–º –ø—Ä–æ–≤–µ—Ä–∫—É –¥–∞—Ç—ã –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –ø–æ—Å—Ç–∞
                latest_post_date = datetime.fromtimestamp(post_texts[0]['date'])
                if (datetime.now() - latest_post_date).days > 60:
                    print(f"‚ö†Ô∏è –ì—Ä—É–ø–ø–∞ –Ω–µ–∞–∫—Ç–∏–≤–Ω–∞ (–ø–æ—Å–ª–µ–¥–Ω–∏–π –ø–æ—Å—Ç {latest_post_date.date()}) ‚Äî –ø—Ä–æ–ø—É—Å–∫–∞–µ–º.")
                    continue

                info = extract_info_from_posts(post_texts, city_name)
                # ... (–æ—Å—Ç–∞–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π)

    # ... (—Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∫—ç—à–∞ –∏ –≤—ã–≤–æ–¥ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏)

    print(f"‚úÖ [VK] –ì–æ—Ä–æ–¥ {city_name} –æ–±—Ä–∞–±–æ—Ç–∞–Ω –∑–∞ {time.time() - start:.2f} —Å–µ–∫")
    print(f"üîç –í—Å–µ–≥–æ –ø—Ä–æ–≤–µ—Ä–µ–Ω–æ –≥—Ä—É–ø–ø: {total_groups_checked}")
