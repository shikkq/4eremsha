
import requests
import re
import time
import json
import os
from datetime import datetime, timedelta
from dotenv import load_dotenv

load_dotenv()

VK_TOKEN = os.getenv("VK_TOKEN")
VK_KEYWORDS = os.getenv("VK_KEYWORDS", "–ø—Ä–∏—é—Ç,–∂–∏–≤–æ—Ç–Ω—ã–µ,–∫–æ—à–∫–∏,—Å–æ–±–∞–∫–∏").split(",")
VK_API_VERSION = "5.199"
CACHE_FILE = "parsed_groups.json"

if os.path.exists(CACHE_FILE):
    with open(CACHE_FILE, "r", encoding="utf-8") as f:
        parsed_groups = set(json.load(f))
else:
    parsed_groups = set()

def save_cache():
    with open(CACHE_FILE, "w", encoding="utf-8") as f:
        json.dump(list(parsed_groups), f)

def get_group_info(group_id):
    url = "https://api.vk.com/method/groups.getById"
    params = {
        "access_token": VK_TOKEN,
        "group_id": group_id,
        "fields": "description,city",
        "v": VK_API_VERSION
    }
    try:
        res = requests.get(url, params=params).json()
        return res.get('response', [{}])[0]
    except Exception as e:
        print(f"[–û—à–∏–±–∫–∞] –ü–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –≥—Ä—É–ø–ø–µ {group_id}: {e}")
        return {}

def is_city_match(group_info, target_city):
    target_lower = target_city.lower()
    description = group_info.get('description', '').lower()

    if 'city' in group_info:
        group_city = group_info['city']['title'].lower()
        if target_lower in group_city:
            print(f"[–ì–æ—Ä–æ–¥] –ù–∞–π–¥–µ–Ω–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –ø–æ –ø–æ–ª—é city: {group_city}")
            return True

    patterns = [
        rf"\b{re.escape(target_lower)}\b",
        rf"\b–≥\.?\s*{re.escape(target_lower)}\b",
        rf"\b{re.escape(target_lower[:5])}\w*\b"
    ]

    if any(re.search(pattern, description) for pattern in patterns):
        print(f"[–ì–æ—Ä–æ–¥] –ù–∞–π–¥–µ–Ω–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –≤ –æ–ø–∏—Å–∞–Ω–∏–∏ –≥—Ä—É–ø–ø—ã")
        return True

    print(f"[–û—Ç–∫–ª–æ–Ω–µ–Ω–æ] –ì–æ—Ä–æ–¥ {target_city} –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –≥—Ä—É–ø–ø–µ")
    return False

def get_group_posts(group_id):
    url = "https://api.vk.com/method/wall.get"
    params = {
        "access_token": VK_TOKEN,
        "owner_id": -group_id,
        "count": 10,
        "filter": "owner",
        "v": VK_API_VERSION
    }
    try:
        res = requests.get(url, params=params).json()
        return res.get("response", {}).get("items", [])
    except Exception as e:
        print(f"[–û—à–∏–±–∫–∞] –ü–æ–ª—É—á–µ–Ω–∏–µ –ø–æ—Å—Ç–æ–≤ –¥–ª—è –≥—Ä—É–ø–ø—ã {group_id}: {e}")
        return []

def extract_post_info(posts):
    relevant_posts = []
    for post in posts:
        text = post.get('text', '')
        if not text.strip():
            print("[–û—Ç–∫–ª–æ–Ω–µ–Ω–æ] –ü–æ—Å—Ç –±–µ–∑ —Ç–µ–∫—Å—Ç–∞")
            continue

        lower_text = text.lower()
        if any(kw.strip() in lower_text for kw in VK_KEYWORDS):
            print(f"[–ü—Ä–∏–Ω—è—Ç] –ü–æ—Å—Ç —Å–æ–¥–µ—Ä–∂–∏—Ç –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞")
            relevant_posts.append({
                'date': datetime.fromtimestamp(post['date']).strftime("%d.%m.%Y"),
                'text': text[:500]
            })
        else:
            print(f"[–û—Ç–∫–ª–æ–Ω–µ–Ω–æ] –ü–æ—Å—Ç –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞: {text[:100]}...")
    return relevant_posts

def search_vk_groups(city_name):
    print(f"\nüîç –ù–∞—á–∏–Ω–∞–µ–º –ø–æ–∏—Å–∫ –¥–ª—è –≥–æ—Ä–æ–¥–∞: {city_name}")
    total_added = 0
    exclusion_keywords = ["–±–∏–∑–Ω–µ—Å", "–º–∞–≥–∞–∑–∏–Ω", "—Ä–µ–∫–ª–∞–º–∞", "–¥–æ—Å—Ç–∞–≤–∫–∞"]

    for keyword in VK_KEYWORDS:
        offset = 0
        while total_added < 10:
            url = "https://api.vk.com/method/groups.search"
            params = {
                "access_token": VK_TOKEN,
                "q": keyword,
                "count": 20,
                "offset": offset,
                "v": VK_API_VERSION
            }

            try:
                response = requests.get(url, params=params).json()
                groups = response.get('response', {}).get('items', [])
                print(f"[{keyword}] –ù–∞–π–¥–µ–Ω–æ –≥—Ä—É–ø–ø: {len(groups)}")

                for group in groups:
                    group_id = abs(group['id'])
                    if group_id in parsed_groups:
                        print(f"[–ü—Ä–æ–ø—É—â–µ–Ω–æ] –ì—Ä—É–ø–ø–∞ —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–∞: {group['name']}")
                        continue

                    group_info = get_group_info(group_id)
                    time.sleep(0.3)

                    if not is_city_match(group_info, city_name):
                        continue

                    group_name = group['name'].lower()
                    if any(bw in group_name for bw in exclusion_keywords):
                        print(f"[–û—Ç–∫–ª–æ–Ω–µ–Ω–æ] –ù–∞–∑–≤–∞–Ω–∏–µ —Å–æ–¥–µ—Ä–∂–∏—Ç —Å—Ç–æ–ø-—Å–ª–æ–≤–æ: {group_name}")
                        continue

                    posts = get_group_posts(group_id)
                    post_info = extract_post_info(posts)

                    if not post_info:
                        print(f"[–û—Ç–∫–ª–æ–Ω–µ–Ω–æ] –ù–µ—Ç –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö –ø–æ—Å—Ç–æ–≤ –≤ –≥—Ä—É–ø–ø–µ {group['name']}")
                        continue

                    # –í–°–¢–ê–í–¨ —Å—é–¥–∞ —Å–≤–æ—é —Ñ—É–Ω–∫—Ü–∏—é —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –ø—Ä–∏—é—Ç–∞
                    # add_shelter(...)

                    parsed_groups.add(group_id)
                    total_added += 1
                    print(f"[‚úÖ –î–æ–±–∞–≤–ª–µ–Ω–∞] –ì—Ä—É–ø–ø–∞: {group['name']}")

                    if total_added >= 10:
                        break

                offset += 20
                if offset >= 100:
                    break

            except Exception as e:
                print(f"[–û—à–∏–±–∫–∞] –û–±—Ä–∞–±–æ—Ç–∫–∞ keyword='{keyword}': {e}")
                break

    save_cache()
    print(f"üèÅ –ü–æ–∏—Å–∫ –∑–∞–≤–µ—Ä—à—ë–Ω. –î–æ–±–∞–≤–ª–µ–Ω–æ –≥—Ä—É–ø–ø: {total_added}")
